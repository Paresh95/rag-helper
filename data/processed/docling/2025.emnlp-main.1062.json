[{"uuid": "120dd4f4-1285-4d57-b723-f1d4ae1f5a64", "text": "Joongmin Shin$^{1}$, Chanjun Park$^{3}$, Jeongbae Park$^{1}$, Jaehyung Seo$^{1,2\u2021}$, Heiseok Lim1,2\u2021 $^{1}$Human-inspired AI Research, Korea University $^{2}$Department of Computer Science and Engineering, Korea University", "label": "text", "section_path": ["MultiDocFusion: Hierarchical and Multimodal Chunking Pipeline for Enhanced RAG on Long Industrial Documents"], "section_refs": ["#/texts/0"], "page_no": 1, "char_len": 222}, {"uuid": "7ed451c5-ff20-4d31-b98f-f34df524fe19", "text": "$^{3}$School of Software, Soongsil University {tlswndals13, insmile, seojae777, limhseok}@korea.ac.kr bcj1210nlp@ssu.ac.kr", "label": "text", "section_path": ["MultiDocFusion: Hierarchical and Multimodal Chunking Pipeline for Enhanced RAG on Long Industrial Documents"], "section_refs": ["#/texts/0"], "page_no": 1, "char_len": 122}, {"uuid": "e241870e-b5cb-4196-ad20-beec86db9a7d", "text": "RAG-based QA has emerged as a powerful method for processing long industrial documents. However, conventional text chunking approaches often neglect the complex structures of long industrial documents, causing information loss and reduced answer quality. To address this, we introduce MultiDocFusion , a multimodal chunking pipeline that integrates: (i) detection of document regions using visionbased document parsing, (ii) text extraction from these regions via OCR, (iii) reconstruction of document structure into a hierarchical tree using large language model (LLM)based document section hierarchical parsing (DSHP-LLM), and (iv) construction of hierarchical chunks through DFS-based Grouping. Extensive experiments across industrial benchmarks demonstrate that MultiDocFusion improves retrieval precision by 8-15% and ANLS QA scores by 2-3% compared to baselines, emphasizing the critical role of explicitly leveraging document hierarchy for multimodal document-based QA. These significant performance gains underscore the necessity of structure-aware chunking in enhancing the fidelity of RAG-based QA systems.", "label": "text", "section_path": ["MultiDocFusion: Hierarchical and Multimodal Chunking Pipeline for Enhanced RAG on Long Industrial Documents"], "section_refs": ["#/texts/0"], "page_no": 1, "char_len": 1116}, {"uuid": "101d5bd1-9ae8-4164-a339-a95c9db30df9", "text": "The emergence of retrieval-augmented generation (RAG) has significantly advanced the capabilities of large language models (LLMs) in handling long and information-dense documents (Lewis et al., 2021; Jeong, 2023; Ge et al., 2023). Central to the success of RAG pipelines is the document chunking strategy, which segments source documents into manageable and semantically coherent units. Despite its importance, existing chunking methods remain predominantly text-centric, relying on fixed-length splits or shallow semantic cues, and fail to account for the rich visual and structural at-", "label": "text", "section_path": ["1 Introduction"], "section_refs": ["#/texts/5"], "page_no": 1, "char_len": 587}, {"uuid": "78f3efa9-209a-4199-8f2d-4976d218b8d1", "text": "\u2021 Co-corresponding authors", "label": "footnote", "section_path": ["1 Introduction"], "section_refs": ["#/texts/5"], "page_no": 1, "char_len": 26}, {"uuid": "e06d43c5-dcda-4d56-816a-29b9353983ac", "text": "tributes inherent in real-world documents (Gong et al., 2020; Gao et al., 2024).", "label": "text", "section_path": ["1 Introduction"], "section_refs": ["#/texts/5"], "page_no": 1, "char_len": 80}, {"uuid": "5974a9e4-d23a-4747-9674-b2026f089469", "text": "This limitation becomes especially problematic in industrial and academic domains where documents often take the form of scanned images, multi-page PDFs, or reports with intricate visual and hierarchical layouts. For instance, visual elements such as tables, figures, and section headers may span multiple pages, while hierarchical section structures encode critical semantic relationships that are lost under naive chunking. Optical Character Recognition (OCR) artifacts further exacerbate this issue by introducing noise and misalignments in the extracted text, thereby degrading both retrieval and QA performance (Tito et al., 2023; Hong et al., 2024). As a result, general RAG systems frequently fail to preserve the documents' semantic continuity, leading to information fragmentation and suboptimal generation quality.", "label": "text", "section_path": ["1 Introduction"], "section_refs": ["#/texts/5"], "page_no": 1, "char_len": 824}, {"uuid": "109108b9-42b3-41b1-bce3-7eccacfac0a2", "text": "While recent advances in vision-based document parsing (DP) and OCR techniques enable the extraction of visually coherent regions such as tables and text blocks (Dosovitskiy et al., 2021; Pfitzmann et al., 2022), these approaches lack an explicit representation of logical structure, particularly the parent-child relationships embedded in hierarchical sectioning (Xing et al., 2024). This structural gap limits their effectiveness in tasks that depend on accurate context reconstruction and long-range reasoning.", "label": "text", "section_path": ["1 Introduction"], "section_refs": ["#/texts/5"], "page_no": 1, "char_len": 513}, {"uuid": "a512b080-912f-44db-8657-66d0bb2258b6", "text": "To bridge this gap, we introduce MultiDocFusion , a multimodal chunking pipeline that explicitly incorporates both visual layout and a document's structural hierarchy into the chunking process. Our framework integrates four key components: (i) detection of document regions and layout structure using vision-based DP, (ii) text extraction from these regions via OCR, (iii) section hierarchical parsing with large language models (DSHPLLM), and (iv) depth-first search (DFS)-based chunk assembly. By reconstructing a document's", "label": "text", "section_path": ["1 Introduction"], "section_refs": ["#/texts/5"], "page_no": 1, "char_len": 526}, {"uuid": "a02515a5-dfaa-4239-a3b9-c34ef5bed1ab", "text": "semantic hierarchy and aligning it with visual segmentation, MultiDocFusion produces structurally faithful and semantically coherent chunks that are better suited for downstream RAG-based QA.", "label": "text", "section_path": ["1 Introduction"], "section_refs": ["#/texts/5"], "page_no": 2, "char_len": 191}, {"uuid": "9684ffad-74ce-4573-9514-00f91cd2d1fb", "text": "We evaluate our approach across diverse document types, such as financial statements, scientific reports, scanned forms, and visually intricate multi-page documents, consistently demonstrating improvements in both retrieval precision and answer accuracy. Our results highlight that explicitly modeling the document's hierarchical structure is essential for robust and context-aware question answering. Our main contributions are summarized as follows:", "label": "text", "section_path": ["1 Introduction"], "section_refs": ["#/texts/5"], "page_no": 2, "char_len": 451}, {"uuid": "3096a216-cdfa-465d-bc0c-d0e7ac10ffa3", "text": "Chunking for QA on Long Industrial Documents Chunking has emerged as an essential strategy for effectively handling long, multi-page documents (Gao et al., 2024). Traditionally, documents have been segmented using Length chunking (Gong et al., 2020) or Semantic chunking (Qu et al., 2025). However, these methods often fail to adequately reflect hierarchical relationships among sections or incorporate visual layout elements such as tables and figures. Recent approaches leveraging LLMs, such as LumberChunker (Duarte et al., 2024) and Perplexity chunking (Zhao et al., 2024), still suffer from contextual", "label": "text", "section_path": ["2 Related Work"], "section_refs": ["#/texts/19"], "page_no": 2, "char_len": 606}, {"uuid": "00d65713-38db-45ac-a6f7-2f45f4305f81", "text": "fragmentation because they lack explicit modeling of document hierarchies (Hong et al., 2024). StyleDFS, which constructs hierarchical trees using font size and style, struggles with scanned documents lacking text layers or irregular layouts (Hong et al., 2024). While end-to-end multimodal models combining textual and visual information have been proposed to mitigate these limitations (Hu et al., 2024; Wang et al., 2024a; Fujitake, 2024), most methods face challenges due to limited context lengths, making it difficult to process entire multi-page documents at a time. Consequently, there is a growing need for chunking methods that comprehensively capture document structure and context (Saad-Falcon et al., 2023; Kang et al., 2024).", "label": "text", "section_path": ["2 Related Work"], "section_refs": ["#/texts/19"], "page_no": 2, "char_len": 739}, {"uuid": "9b3bed20-1c98-49ba-acf5-eb0f275b1d8a", "text": "Document Parsing and Hierarchical Parsing Recent studies in Visual Question Answering (VQA) have increasingly focused on document parsing (DP), aiming to segment PDFs and imagebased documents into visual components such as tables, figures, and text blocks (Dosovitskiy et al., 2021; Pfitzmann et al., 2022). However, these object-detection-centric approaches inherently lack the capability to fully reconstruct semantic hierarchical relationships, such as the relationship between sections \"1.2\" and \"1.2.1\" (Rausch et al., 2023; Wang et al., 2024a). Document hierarchical parsing (DHP) methods have been proposed to address these issues (Rausch et al., 2021, 2023; Zhang et al., 2024c), but their applicability remains limited to structured templates or certain document types, struggling with scanned or irregularly formatted documents (Wang et al., 2024b; Xing et al., 2024). However, LLMs have emerged as promising candidates for DHP tasks due to their advanced text understanding and long-context handling capabilities (Fujitake, 2024). LLMs still face challenges in inferring hierarchical semantic connections between sections, necessitating additional fine-tuning or specialized instructiontuning methods (Zhang et al., 2024b; Wang et al., 2024a; Tabatabaei et al., 2025). While existing approaches may capture either visual layout or textual content, they fail to unify structural and semantic hierarchies. The MultiDocFusion pipeline addresses this gap by systematically combining visual region detection, OCR, and LLM-based hierarchical parsing to enable accurate, context-aware chunking of long industrial documents.", "label": "text", "section_path": ["2 Related Work"], "section_refs": ["#/texts/19"], "page_no": 2, "char_len": 1627}, {"uuid": "e655d849-9b71-400d-bd42-23b43e59fa73", "text": "Figure 1: The pipeline for MultiDocFusion . The figure illustrates the step-by-step process for handling a long industrial document. (a) DP extracts layout structures; (b) OCR recognizes and annotates text; (c) DSHP-LLM constructs a hierarchical tree from identified section headers and general nodes; (d) DFS-based Grouping constructs coherent hierarchical chunks for retrieval tasks. The color-coded blocks represent document elements: yellow for Root and Title, red for Section Headers, and green for general nodes (tables, figures, and text blocks).", "label": "caption", "section_path": ["2 Related Work"], "section_refs": ["#/texts/19"], "page_no": 3, "char_len": 553}, {"uuid": "1e39b5b1-2399-409c-a788-3f2c707135e7", "text": "MultiDocFusion ( Multimodal Document Structure Fusion ) is a pipeline designed to effectively integrate visual layouts and hierarchical semantic structures of long industrial documents, enhancing chunking and retrieval performance. The term \"MultiDoc\" emphasizes the pipeline's capability to handle diverse document formats frequently encountered in industrial settings such as PDFs, scanned images, and documents with complex layouts, and to support corpus-level multidocument RAG scenarios, enabling retrievalaugmented generation across large collections of documents. Meanwhile, \"Fusion\" highlights the integration of visual information, textual content, and hierarchical document analysis to produce refined and contextually accurate chunks. The pipeline consists of four stages: (a) DP (Document Parsing), (b) OCR (Optical Character Recognition), (c) DSHP-LLM (Document Section Hierarchical Parsing with LLM), and (d) DFS-based Grouping. Figure 1 provides an overview of this four-stage process and the resulting hierarchical chunks. Below, we detail each stage using the components and terminology shown in the figure.", "label": "text", "section_path": ["3 MultiDocFusion"], "section_refs": ["#/texts/25"], "page_no": 3, "char_len": 1124}, {"uuid": "b18b7d13-31fc-4efb-bdc9-8723eb410d9d", "text": "As shown in (a), DP examines each page of a long industrial document to identify and extract its Layout Structure .", "label": "text", "section_path": ["3 MultiDocFusion", "3.1 DP (Document Parsing)"], "section_refs": ["#/texts/25", "#/texts/27"], "page_no": 3, "char_len": 115}, {"uuid": "2c26615d-dce4-4e73-b0e4-a2b261d15551", "text": "Process Advanced vision models detect Titles, Section Headers, text blocks, tables, figures, etc. Each detected segment is assigned bounding-box coordinates and segment type. The pipeline constructs a page-by-page Layout Structure that captures the spatial arrangement of all segments.", "label": "text", "section_path": ["3 MultiDocFusion", "3.1 DP (Document Parsing)"], "section_refs": ["#/texts/25", "#/texts/27"], "page_no": 3, "char_len": 285}, {"uuid": "5a7b6c87-1b34-4579-a4d3-eb2f2c7c40fc", "text": "Output For each page, DP generates metadata including page numbers, segment IDs, segment types, and bounding box coordinates. This Layout Structure is passed to the OCR stage.", "label": "text", "section_path": ["3 MultiDocFusion", "3.1 DP (Document Parsing)"], "section_refs": ["#/texts/25", "#/texts/27"], "page_no": 3, "char_len": 175}, {"uuid": "c4fe3f82-9b6a-4de8-8492-17d721fcad40", "text": "As described in (b), OCR processes the Layout Structure from DP to extract text from each bounding box, resulting in Annotated Layout .", "label": "text", "section_path": ["3 MultiDocFusion", "3.2 OCR (Optical Character Recognition)"], "section_refs": ["#/texts/25", "#/texts/31"], "page_no": 3, "char_len": 135}, {"uuid": "f2c6bcf2-9e38-4ad8-9eb1-79628e8b9a93", "text": "Input The page-by-page Layout Structure with bounding boxes and segment information from DP.", "label": "text", "section_path": ["3 MultiDocFusion", "3.2 OCR (Optical Character Recognition)"], "section_refs": ["#/texts/25", "#/texts/31"], "page_no": 3, "char_len": 92}, {"uuid": "97bd2d0a-83b3-40ad-86e2-782dd5fd5a81", "text": "Process Each segment image is sent to OCR engines tailored to the document's languages and fonts. The recognized text is then linked back to the corresponding bounding box.", "label": "text", "section_path": ["3 MultiDocFusion", "3.2 OCR (Optical Character Recognition)"], "section_refs": ["#/texts/25", "#/texts/31"], "page_no": 4, "char_len": 172}, {"uuid": "0195245e-a4b6-4b46-82e1-54c7cbdf265c", "text": "Output The Annotated Layout merges bounding boxes, segment types, and recognized text into structured metadata, preparing the necessary inputs for the subsequent processing stage.", "label": "text", "section_path": ["3 MultiDocFusion", "3.2 OCR (Optical Character Recognition)"], "section_refs": ["#/texts/25", "#/texts/31"], "page_no": 4, "char_len": 179}, {"uuid": "eb9d837f-6d07-4406-abb0-1412269d1508", "text": "As depicted in (c), DSHP-LLM constructs a Document Hierarchical Tree by identifying, ordering, and attaching section headers along with other nodes based on Parent-Child relationships.", "label": "text", "section_path": ["3 MultiDocFusion", "3.3 DSHP-LLM"], "section_refs": ["#/texts/25", "#/texts/37"], "page_no": 4, "char_len": 184}, {"uuid": "a025de55-dc5a-4985-95a7-f7f71abf6c57", "text": "Model Setup DSHP-LLM is built upon an LLM backbone and is instruction-tuned on public datasets of document hierarchies (Zhang et al., 2024a). To improve training efficiency, we employ LoRA-based parameter-efficient fine-tuning (PEFT) (Hu et al., 2021; Han et al., 2024). Hyperparameters and further details are provided in Appendix A.2.", "label": "text", "section_path": ["3 MultiDocFusion", "3.3 DSHP-LLM"], "section_refs": ["#/texts/25", "#/texts/37"], "page_no": 4, "char_len": 336}, {"uuid": "7bfddea3-bc25-4bc1-a82c-471923e2a62a", "text": "Input The DSHP-LLM receives a Header List , which consists of candidate section headers extracted during the DP and OCR stages from the Annotated Layout .", "label": "text", "section_path": ["3 MultiDocFusion", "3.3 DSHP-LLM"], "section_refs": ["#/texts/25", "#/texts/37"], "page_no": 4, "char_len": 154}, {"uuid": "40bf8d8b-71b6-482c-bbee-46b6275280a5", "text": "Process The DSHP-LLM initially performs Header Tree construction by analyzing the Header List and assigning each header a unique identifier and parent reference (e.g., ID:3 Parent:2 ), resulting in an initial hierarchical structure (e.g., Root \u2192 Title \u2192 Section 1 \u2192 Section 1.1 ). Next, it proceeds to link general nodes, utilizing the All Segments list maintained from the DP stage. This list includes tables, figures, text blocks, and other document elements sorted by spatial coordinates, such as page number and bounding box position. As the DSHP-LLM traverses the Header Tree, it sequentially scans through the All Segments list . General segments encountered before reaching the next header from the Header List are attached as child nodes of the current header node. This ensures accurate grouping of tables, figures, and text blocks, preserving both logical and spatial document structures.", "label": "text", "section_path": ["3 MultiDocFusion", "3.3 DSHP-LLM"], "section_refs": ["#/texts/25", "#/texts/37"], "page_no": 4, "char_len": 898}, {"uuid": "21e9004a-78e1-42f9-8420-fd32994a6096", "text": "Output The output is a fully Document Hierarchical Tree explicitly detailing the hierarchical placement of section headers and associated general nodes (e.g., Root \u2192 Title \u2192 Section", "label": "text", "section_path": ["3 MultiDocFusion", "3.3 DSHP-LLM"], "section_refs": ["#/texts/25", "#/texts/37"], "page_no": 4, "char_len": 181}, {"uuid": "e77028e2-37b4-4b15-8d49-5e6ced05bedd", "text": "1 \u2192 Section 1.1 \u2192 Text ). By integrating LLM-identified headers with spatially sorted child nodes, the pipeline maintains coherent logical and visual relationships. For example prompts and outputs, refer to Table 10 .", "label": "text", "section_path": ["3 MultiDocFusion", "3.3 DSHP-LLM"], "section_refs": ["#/texts/25", "#/texts/37"], "page_no": 4, "char_len": 217}, {"uuid": "a28f9c3c-67ea-479f-a608-08132db5ba1b", "text": "As illustrated in (d), DFS-based Grouping performs a depth-first traversal of the Document Hierarchical Tree to construct coherent Hierarchical Chunks (e.g., Chunk1, Chunk2, Chunk3, . . . ). During this stage, the hierarchical structure is explicitly reflected within each chunk using Markdown headers, where each chunk's depth corresponds directly to the heading level. Detailed algorithms are provided in Appendix A.5.", "label": "text", "section_path": ["3 MultiDocFusion", "3.4 DFS-based Grouping"], "section_refs": ["#/texts/25", "#/texts/44"], "page_no": 4, "char_len": 420}, {"uuid": "4a377ca2-3891-4de0-a809-630133874d0b", "text": "Input The Document Hierarchical Tree from DSHP-LLM and text corresponding to each node in the tree.", "label": "text", "section_path": ["3 MultiDocFusion", "3.4 DFS-based Grouping"], "section_refs": ["#/texts/25", "#/texts/44"], "page_no": 4, "char_len": 99}, {"uuid": "001bd0bb-42a1-447b-bef0-79b3dabf448c", "text": "Process In this process, a virtual node called FAKE_ROOT is created, which points directly to the actual root node. The algorithm performs a recursive traversal of the nodes following a depthfirst approach, aggregating the text content from parent nodes along with their child nodes to preserve the contextual information. When the aggregated text length surpasses a predefined threshold (max_len), the algorithm splits the chunk at that specific point.", "label": "text", "section_path": ["3 MultiDocFusion", "3.4 DFS-based Grouping"], "section_refs": ["#/texts/25", "#/texts/44"], "page_no": 4, "char_len": 453}, {"uuid": "21773cdb-6f41-44cc-80a8-bbac496d7353", "text": "Output A list of Hierarchical Chunks that encapsulate entire sections or sub-sections, thereby minimizing token waste. The resulting chunks explicitly represent the document's hierarchical structure via Markdown headers corresponding to each node's depth. For example, if \"1\" is a parent of \"1.1,\" both might be combined into \"Chunk4\" to preserve continuity in retrieval/QA tasks. An illustrative example is shown below:", "label": "text", "section_path": ["3 MultiDocFusion", "3.4 DFS-based Grouping"], "section_refs": ["#/texts/25", "#/texts/44"], "page_no": 4, "char_len": 420}, {"uuid": "79279773-f10e-4830-b688-185703b7e4d9", "text": "# Document Title\n## Section 1 {name}\n## Section 1.1 {name}\nSection 1.1 {Text Content...}", "label": "code", "section_path": ["3 MultiDocFusion", "3.4 DFS-based Grouping"], "section_refs": ["#/texts/25", "#/texts/44"], "page_no": 4, "char_len": 88}, {"uuid": "925c5f7f-7fef-4206-aeef-832a8a091cbd", "text": "By combining Layout Structure (from DP) with recognized text (from OCR) into an Annotated Layout , and then applying the DSHP-LLM model to build a Header Tree , MultiDocFusion captures both spatial and semantic relationships in long industrial documents. The final DFS-based Grouping stage yields Hierarchical Chunks that main-", "label": "text", "section_path": ["3 MultiDocFusion", "3.4 DFS-based Grouping"], "section_refs": ["#/texts/25", "#/texts/44"], "page_no": 4, "char_len": 327}, {"uuid": "7aeba392-3d2a-473d-87ae-479f8c7e9a74", "text": "tain these relationships, clearly marked by Markdown headers, outperforming traditional text-only chunking in real-world retrieval and QA scenarios.", "label": "text", "section_path": ["3 MultiDocFusion", "3.4 DFS-based Grouping"], "section_refs": ["#/texts/25", "#/texts/44"], "page_no": 5, "char_len": 148}, {"uuid": "2fca4ead-05f7-4c1c-a8c4-d5a3a00d8659", "text": "This section briefly describes the experimental settings for training and evaluating the DSHP-LLM model and the RAG-based VQA system for multipage documents. We utilize various datasets and model configurations, with additional details (e.g., dataset statistics, hyperparameters, and model setups) provided in the Appendix A.", "label": "text", "section_path": ["4 Experimental Settings"], "section_refs": ["#/texts/53"], "page_no": 5, "char_len": 325}, {"uuid": "bbe46507-7ff0-4360-a6ed-7de39d4c19dd", "text": "Datasets For DSHP-LLM training and testing, we combine documents from DocHieNet (Xing et al., 2024) and HRDH (Ma et al., 2023). These datasets include diverse domains and complex layouts, making them suitable for evaluating the generalization of hierarchical parsing models. For multi-page RAG-based VQA performance evaluation, we use four datasets: DUDE (Landeghem et al., 2023), MPVQA (Tito et al., 2023), CUAD (Hendrycks et al., 2021), and MOAMOB (Hong et al., 2024). These datasets encompass financial reports, contracts, scanned documents, and various structures, allowing comprehensive evaluation of chunking and retrieval performance. For each dataset, we index all test documents jointly and retrieve topk chunks from the entire corpus (not restricted to a gold document). Unless stated otherwise, k = 4 . This corpus-level setup reflects realistic deployment and stresses cross-document disambiguation.", "label": "text", "section_path": ["4 Experimental Settings"], "section_refs": ["#/texts/53"], "page_no": 5, "char_len": 911}, {"uuid": "c37800cc-6e17-40fa-b9a1-853309433917", "text": "Models DP is performed with object detection models such as DETR (Carion et al., 2020) and VGT (Da et al., 2023), while OCR text extraction uses Tesseract (Smith, 2007), EasyOCR (Vedhaviyassh et al., 2022), and TrOCR (Li et al., 2022). The DSHP-LLM, which infers hierarchical parent-child relationships among document section headers, is trained via instruction tuning on LLMs such as Llama-3.2-3B (Grattafiori et al., 2024), Qwen-2.5-3B (Yang et al., 2024), and Mistral-8B (AI, 2024) to predict JSON-structured hierarchies. In the retrieval stage, chunk embeddings are generated using BGE (Chen et al., 2024), E5 (Wang et al., 2024c), and BM25 (Robertson and Zaragoza, 2009). Topk retrieved chunks are then fed into LLMs (e.g., Llama-based models) for final answer generation.", "label": "text", "section_path": ["4 Experimental Settings"], "section_refs": ["#/texts/53"], "page_no": 5, "char_len": 777}, {"uuid": "fae7d707-72b9-4694-90f0-772edb8a60e3", "text": "Table 1: Performance on DHP datasets (DocHieNet + HRDH) for DSHP-LLM (section headers). \u21aa \u2192 : DSHPLLM applied. Bold : improvement over baseline.", "label": "caption", "section_path": ["4 Experimental Settings"], "section_refs": ["#/texts/53"], "page_no": 5, "char_len": 144}, {"uuid": "2afd2de9-e283-4d98-a21d-4c0ac7ab06c7", "text": "Evaluation We evaluate the DSHP-LLM performance using accuracy, F1, and TEDS (Zhong et al., 2020) metrics. Retrieval quality is measured using Precision, Recall, and nDCG (J\u00e4rvelin and Kek\u00e4il\u00e4inen, 2002), while generated VQA answers are quantitatively assessed via ANLS (Biten et al., 2019), ROUGE-L (Lin, 2004), and METER (Banerjee and Lavie, 2005).", "label": "text", "section_path": ["4 Experimental Settings"], "section_refs": ["#/texts/53"], "page_no": 5, "char_len": 350}, {"uuid": "94c5f05a-35da-41fe-bb79-349455cbe149", "text": "In this section, we comprehensively evaluate the performance of the proposed MultiDocFusion pipeline using the experimental setup. The evaluation consists of: (1) DSHP-LLM performance comparison across different fine-tuned LLMs, (2) retrieval performance comparison among different chunking methods, (3) QA performance analysis, and (4) retrieval robustness analysis under various DP, OCR, and embedding model combinations. To provide objective comparative benchmarks, we include several baseline chunking methodologies, such as Length chunking (Gong et al., 2020), Semantic Chunking (Qu et al., 2025), LumberChunker (Duarte et al., 2024), Perplexity chunking (Zhao et al., 2024), and Structure-based Chunking (W/O DSHP-LLM). Detailed chunking methods are explained in Appendix A.3.", "label": "text", "section_path": ["5 Experimental Results"], "section_refs": ["#/texts/59"], "page_no": 5, "char_len": 782}, {"uuid": "61529cd2-ec42-4a51-b213-ec0d504f306f", "text": "Table 1 summarizes the performance results of section hierarchy parsing on the DocHieNet and HRDH datasets. Each dataset has distinct characteristics: DocHieNet comprises documents from diverse domains, including reports, academic papers, and industrial documents, with complex", "label": "text", "section_path": ["5 Experimental Results", "5.1 DSHP-LLM Performance"], "section_refs": ["#/texts/59", "#/texts/61"], "page_no": 5, "char_len": 277}, {"uuid": "14de2552-cd10-4442-9d91-614c26004599", "text": "Table 2: Retrieval performance by Chunking Method (Average Recall, Precision, nDCG for topk = 1 \u223c 4 ), Best scores are in bold .", "label": "caption", "section_path": ["5 Experimental Results", "5.1 DSHP-LLM Performance"], "section_refs": ["#/texts/59", "#/texts/61"], "page_no": 6, "char_len": 128}, {"uuid": "9bafa030-beeb-4db9-b9e5-8d3e7374130b", "text": "scanned images, while HRDH focuses on academic papers characterized by intricate layouts. The experimental results show that GPT-4, used without any fine-tuning, demonstrated limited performance on both DocHieNet (TEDS 0.6961) and HRDH (TEDS 0.3342), indicating similar deficiencies across other general-purpose LLMs. This suggests that general pre-training alone is insufficient for effective section hierarchy parsing. Conversely, applying our proposed DSHP-LLM approach significantly improved performance (measured by TEDS) across both datasets, with varying degrees of improvement depending on model and dataset characteristics. Specifically, for the diverse domains and layout complexities in DocHieNet, Mistral-8B +16.71% and Llama-3.2-3B +20.85% showed substantial improvements. For HRDH, characterized by complex yet relatively regular academic document structures, Mistral-8B +52.25% and Qwen-2.5-3B +49.24% achieved the most significant enhancements. These results clearly indicate that general-purpose LLMs have inherent limitations when performing section hierarchy parsing tasks, underscoring the necessity for dataset-specific fine-tuning. Furthermore, the results emphasize the importance of selecting appropriate models and training strategies tailored to the unique characteristics of each dataset. Based on these findings, we selected the fine-tuned Mistral8B model as the backbone of our DSHP-LLM for integration into the MultiDocFusion chunking pipeline, and subsequently evaluated its performance in various multi-page VQA scenarios against other chunking methods.", "label": "text", "section_path": ["5 Experimental Results", "5.1 DSHP-LLM Performance"], "section_refs": ["#/texts/59", "#/texts/61"], "page_no": 6, "char_len": 1585}, {"uuid": "e579c53f-0878-4e08-8d0d-454a7d1315c2", "text": "Table 2 presents the average Recall, Precision, and nDCG values for topk = 1 \u223c 4 retrieval re-", "label": "text", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 6, "char_len": 94}, {"uuid": "48e7be35-5043-4b0f-a674-259f0d319ef3", "text": "sults, comparing various chunking methods across four multi-page VQA datasets: DUDE, MPVQA, CUAD, and MOAMOB.", "label": "text", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 6, "char_len": 109}, {"uuid": "7ee9de54-9163-46d9-a269-82b44e126134", "text": "MultiDocFusion consistently achieved the best overall retrieval performance across most datasets. In particular, MultiDocFusion demonstrated significant advantages in retrieval accuracy on DUDE (Recall 0.2927, Precision 0.2001, nDCG 0.2505) and MPVQA (Recall 0.2705, Precision 0.1759, nDCG 0.2131), clearly outperforming other methods. These results underscore MultiDocFusion 's effectiveness even under challenging conditions such as the diverse domains and complex document structures inherent in the DUDE dataset, and the varied layouts characteristic of the MPVQA dataset. On CUAD, while LumberChunker attained the highest Recall (0.9031), MultiDocFusion showed superior Precision (0.8651) and nDCG (0.8819), confirming its capability for precise retrieval in specialized legal documents. Moreover, in MOAMOB, an extreme scenario characterized by highly intricate document structures and challenging questions within a specialized nuclear domain, MultiDocFusion (Recall 0.6758, Precision 0.6184, nDCG 0.6554) markedly outperformed other approaches across all evaluation metrics, demonstrating robust and superior performance even with a limited dataset.", "label": "text", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 6, "char_len": 1157}, {"uuid": "b2237be9-e8c5-43b7-8565-fdef9e458d04", "text": "Additionally, compared to methods solely dependent on LLM-based chunking (e.g., LumberChunker, Perplexity chunking), MultiDocFusion significantly enhanced retrieval performance by explicitly capturing and utilizing the hierarchical structure of documents. Specifically, in datasets with complex document structures such as DUDE and MPVQA, simple LLM-based chunking methods failed to sufficiently incorporate structural relationships or context between sections, thus limiting retrieval performance. Conversely, MultiDoc-", "label": "text", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 6, "char_len": 520}, {"uuid": "65bb3e34-8e44-4828-835f-e2d615c4f206", "text": "Table 4: Average performance of Chunking Methods by DP model (topk = 1 \u223c 4 nDCG).", "label": "caption", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 8, "char_len": 81}, {"uuid": "0f8dbb8c-fe78-46fe-96a7-9569f1b68e68", "text": "Table 5: Average performance of Chunking Methods by OCR model (topk = 1 \u223c 4 nDCG).", "label": "caption", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 8, "char_len": 82}, {"uuid": "13402451-d9b9-45d2-94ff-a39de10704db", "text": "ent chunking methods across three DP model environments: DETR, DiT, and VGT. Overall, MultiDocFusion achieved the highest average performance (0.5017) and consistently delivered superior results across all individual DP models. Particularly noteworthy is its substantial improvement of up to +27.64% over the lowest-performing Semantic chunking method in the VGT environment. This clearly demonstrates that MultiDocFusion , by explicitly incorporating hierarchical document structures, consistently maintains robust and superior performance regardless of variations in DP models.", "label": "text", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 8, "char_len": 579}, {"uuid": "30531032-1830-42ee-b0ec-df2326f744b8", "text": "(2) Comparison across OCR Models Table 5 compares the average nDCG scores of various chunking methods across different OCR models, namely EasyOCR, Tesseract, and TrOCR. MultiDocFusion consistently achieved the highest performance (avg 0.4949) and notably outperformed other methods, particularly in EasyOCR (avg 0.5681) and Tesseract (avg 0.5068) settings. Even with TrOCR, where the overall performance was lower, MultiDocFusion maintained a relatively high score (avg 0.4097), demonstrating that hierarchical structure-based chunking remains robust and provides stable retrieval performance despite variations in OCR quality.", "label": "text", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 8, "char_len": 627}, {"uuid": "0f2d801a-e2a5-48f8-88f4-756cd3c38840", "text": "(3) Comparison across Embedding Models Table 6 shows the average nDCG performance across various embedding models (BGE, E5, and BM25) for each chunking method. On average, MultiDocFusion achieved the highest overall", "label": "text", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 8, "char_len": 215}, {"uuid": "1bd775d6-e063-43eb-9afc-b8113df2c617", "text": "Table 6: Average performance of Chunking Methods by embedding model (topk = 1 \u223c 4 nDCG).", "label": "caption", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 8, "char_len": 88}, {"uuid": "c03c7ae0-3738-445f-99e2-4f5695cfc586", "text": "performance (0.5061), consistently outperforming other chunking methods across all embedding environments. In particular, MultiDocFusion recorded the best performance (0.5213) in the BGE embedding environment. These results demonstrate that chunking methods leveraging hierarchical document structure are robust and effective in enhancing retrieval accuracy, irrespective of the embedding model utilized.", "label": "text", "section_path": ["5 Experimental Results", "5.2 Retrieval Performance in Different Chunking Methods"], "section_refs": ["#/texts/59", "#/texts/66"], "page_no": 8, "char_len": 404}, {"uuid": "af15b69a-0341-44fa-90cf-1317c9d83972", "text": "This work targets a core bottleneck in RAG over long industrial documents: context fragmentation caused by text-only chunking that ignores visual layout and explicit selection hierarchy. We formalize this problem and introduce MultiDocFusion , a structured multimodal pipeline that (i) parses page-level layout regions (DP), (ii) extracts text with OCR, (iii) reconstructs an explicit section hierarchy with DSHP-LLM, and (iv) assembles hierarchical chunks via DFS to preserve both spatial and semantic context.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 8, "char_len": 511}, {"uuid": "51d51bc9-fa25-4e5b-a125-70738efcc509", "text": "Evaluated under a corpus-level setting on four multi-page VQA benchmarks, MultiDocFusion consistently outperforms baseline chunking methods in retrieval and QA. DSHP-LLM, fine-tuned for hierarchical parsing, accurately reconstructs complex section structures and surpasses general-purpose LLMs (e.g., GPT-4) on DHP datasets. The gains hold across diverse domains and layouts and remain stable under different DP, OCR, and embedding choices, underscoring the pipeline's practical reliability.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 8, "char_len": 491}, {"uuid": "ef1654b8-6d3a-44c8-808c-f0cec5c05970", "text": "Taken together, these results support a clear conclusion: Hierarchy-aware, visually grounded chunking should be a first-class design principle for RAG on long, complex, and often scanned industrial documents. By aligning visual segmentation with an explicit document tree and reflecting it in chunk boundaries, MultiDocFusion reduces contextual breakage and yields more faithful re-", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 8, "char_len": 382}, {"uuid": "7c9272d4-d90e-4d10-8eb8-fdfd5e415f08", "text": "trieval and answers.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 20}, {"uuid": "c6693194-3dca-4f60-bc6c-5046599db528", "text": "Although the MultiDocFusion chunking pipeline effectively incorporates document hierarchy to improve retrieval and QA, several limitations remain.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 146}, {"uuid": "fde15e19-7176-4cbe-a994-81ae4704305e", "text": "Limited visual grounding of DSHP-LLM Our DSHP-LLM was trained on DHP datasets, which do not provide fine-grained layout signals such as font size/style, color, whitespace, alignment/ruling lines, or column structure. As the model is inherently LLM-centric and primarily conditioned on OCR text with coarse bounding boxes, it underutilizes these visual cues that are often decisive for reliable hierarchy reconstruction in scanned or visually complex pages. Future work should incorporate detailed layout features and, more broadly, visually ground DSHP-LLM via multimodal document encoders or VLM backbones to enable more accurate structural analysis.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 651}, {"uuid": "1eaf7714-929e-4d66-9428-6a6c7febbce7", "text": "Graph-structured retrieval not evaluated Because MultiDocFusion induces an explicit hierarchical document graph (headers \u2192 subheaders \u2192 content blocks) with typed relations (e.g., parent-child, reading order), it can naturally be instantiated as a GraphRAG pipeline that retrieves and reasons over nodes and paths. This formulation is likely to better support multi-hop and other reasoning-intensive tasks. However, we did not systematically validate this direction, as the present work focuses on verifying multimodal hierarchical chunking under standard RAG settings. Future research should rigorously evaluate graphaugmented retrieval and reasoning on benchmarks requiring multi-hop, compositional reasoning, and cross-page evidence aggregation.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 748}, {"uuid": "032bcf46-1281-4c5d-ae27-ce8e44fe02c5", "text": "Error propagation and end-to-end alternatives While a serial, multi-module pipeline is pragmatic and familiar in industrial settings, such a design is inherently susceptible to error propagation: mistakes in earlier-stage components (DP/OCR) can cascade into DSHP-LLM, DFS-based chunking, retrieval, and ultimately QA. To mitigate this risk, future work should investigate the substitutability of VLM-based end-to-end models as drop-in replacements or hybrid components that jointly optimize visual parsing, hierarchical structuring, chunking, and retrieval/answering. Such end-toend formulations may reduce the accumulation", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 624}, {"uuid": "ee416b6f-08e4-4035-83e8-20a36fb3200b", "text": "of earlier-stage noise and provide stronger crossmodal consistency, albeit with trade-offs in controllability and interpretability that warrant careful study.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 158}, {"uuid": "433f41ff-3b51-44fb-a307-8d20868f7f94", "text": "Computational overhead Hierarchical chunking duplicates parent context across multiple children to preserve coherence, which can increase index size, retrieval latency, and storage costs. Budget-aware chunking, graph pruning, and nodelevel caching/deduplication are practical mitigations to explore.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 299}, {"uuid": "638ee57a-6655-497b-b905-0b0d7bb07b77", "text": "The primary objective of this research is to enhance multimodal document parsing and questionanswering capabilities; however, ethical considerations must be carefully addressed when applying this technology. First, documents processed by the pipeline may contain sensitive information such as personal data, copyrighted materials, or proprietary business content. Thus, meticulous care must be exercised in data collection, processing, and usage to ensure strict adherence to privacy regulations and data security standards.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 524}, {"uuid": "92db924e-c29f-4560-9c72-fff042fbe85a", "text": "Second, despite aiming to provide accurate information, the proposed system could inadvertently generate incorrect or biased responses, potentially misleading users. When deploying the system in practical settings, clear guidelines for accountability and measures against misuse should be implemented.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 301}, {"uuid": "cf94fd15-efd3-4083-96dd-9460bc209157", "text": "This work was supported by Institute for Information & communications Technology Promotion(IITP) grant funded by the Korea government(MSIT) (RS-2024-00398115, Research on the reliability and coherence of outcomes produced by Generative AI). This research was supported by Basic Science Research Program through the National Research Foundation of Korea(NRF) funded by the Ministry of Education(NRF-2021R1A6A1A03045425). This work was supported by the Commercialization Promotion Agency for R&D Outcomes(COMPA) grant funded by the Korea government(Ministry of Science and ICT)(2710086166)", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 9, "char_len": 587}, {"uuid": "b14c4b8c-29c5-414e-93a5-df4f09ffd481", "text": "Mistral AI. 2024. Mistral-8b-instruct-2410. https://huggingface.co/mistralai/ Ministral-8B-Instruct-2410 . Accessed: 2024-05-16.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 128}, {"uuid": "dca93aef-8564-409c-bd05-ed319c7bab3d", "text": "Satanjeev Banerjee and Alon Lavie. 2005. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the ACL workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization , pages 65-72.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 276}, {"uuid": "dc72a015-a83a-473e-a25a-8f3cd143a61e", "text": "Ali Furkan Biten, Ruben Tito, Andres Mafla, Lluis Gomez, Marcal Rusinol, Ernest Valveny, CV Jawahar, and Dimosthenis Karatzas. 2019. Scene text visual question answering. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) , pages 4291-4301.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 271}, {"uuid": "76ae431b-1df7-426e-8829-4332e6dc18fd", "text": "Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko. 2020. End-to-end object detection with transformers. In Computer Vision - ECCV 2020 , pages 213-229.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 210}, {"uuid": "820208fd-37ce-44d1-9647-1a2b99c02c08", "text": "Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024. Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through selfknowledge distillation. Preprint , arXiv:2402.03216.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 234}, {"uuid": "ea97bfa1-8ce7-4477-b830-d761f8ca0da1", "text": "Cheng Da, Chuwei Luo, Qi Zheng, and Cong Yao. 2023. Vision grid transformer for document layout analysis. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 189}, {"uuid": "f85f1520-9119-4ff3-a1d9-e8a6110f64ad", "text": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, and et al. 2021. An image is worth 16x16 words: Transformers for image recognition at scale. In Proceedings of the 9th International Conference on Learning Representations (ICLR) .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 253}, {"uuid": "90a70568-2682-45a9-94c1-a9c27dc0b86c", "text": "Andr\u00e9 V Duarte, Jo\u00e3o Marques, Miguel Gra\u00e7a, Miguel Freire, Lei Li, and Arlindo Llo Oliveira. 2024. Lemberchunker: Long-form narrative document segmentation. arXiv preprint arXiv:2406.17526 .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 190}, {"uuid": "bf3a2007-d929-40d5-a5ca-5c33fa1ab3f4", "text": "Masato Fujitake. 2024. LayoutLLM: Large language model instruction tuning for visually rich document understanding. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LRECOLING 2024) , pages 10219-10224, Torino, Italia. ELRA and ICCL.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 306}, {"uuid": "5ccac344-41f7-4986-9507-31a28f942f02", "text": "Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. 2024. Retrieval-augmented generation for large language models: A survey. Preprint , arXiv:2312.10997 .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 221}, {"uuid": "f984a1e4-4a6f-472d-9283-913961f5ba1d", "text": "J. Ge, Steve Sun, Joseph Owens, Victor Galvez, O. Gologorskaya, Jennifer C Lai, Mark J Pletcher, and", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 100}, {"uuid": "ae7459c8-12de-423f-a409-7a6eb0db070c", "text": "Ki Lai. 2023. Development of a liver diseasespecific large language model chat interface using retrieval augmented generation. medRxiv .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 136}, {"uuid": "7f40938a-f246-4298-913d-ebefff3aa732", "text": "Hongyu Gong, Yelong Shen, Dian Yu, Jianshu Chen, and Dong Yu. 2020. Recurrent chunking mechanisms for long-text machine reading comprehension. pages 6751-6761.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 159}, {"uuid": "9a10180b-73a3-469c-b2aa-a12fabff5b34", "text": "Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, and Abhishek Kadian. 2024. The llama 3 herd of models. Preprint , arXiv:2407.21783 .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 152}, {"uuid": "baa11a7f-19a8-42bf-98da-cf82a835a579", "text": "Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, and Sai Qian Zhang. 2024. Parameter-efficient finetuning for large models: A comprehensive survey. Preprint , arXiv:2403.14608 .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 173}, {"uuid": "758c7693-2516-4103-92d9-bffeda8b754d", "text": "Dan Hendrycks, Collin Burns, Anya Chen, and Spencer Ball. 2021. Cuad: An expert-annotated nlp dataset for legal contract review. NeurIPS .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 138}, {"uuid": "73ec3813-3ba5-4158-9b59-0974a89d87a0", "text": "Seongtae Hong, Jooning Shin, Jaehyung Seo, Taemin Lee, Jeongbae Park, Cho Man Young, Byeongho Choi, and Heuseok Lim. 2024. Intelligent predictive maintenance RAG framework for power plants: Enhancing QA with StyleDFS and domain specific instruction tuning. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track , pages 805-820, Miami, Florida, US. Association for Computational Linguistics.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 442}, {"uuid": "07747a3b-07c3-4bec-9594-a80f49185c1c", "text": "Anwen Hu, Haiyang Xu, Jiabo Ye, Ming Yan, Liang Zhang, Bo Zhang, Ji Zhang, Qin Jin, Fei Huang, and Jingren Zhou. 2024. mPLUG-DocOwl 1.5: Unified structure learning for OCR-free document understanding. In Findings of the Association for Computational Linguistics: EMNLP 2024 , pages 30963120, Miami, Florida, USA. Association for Computational Linguistics.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 355}, {"uuid": "ea10698d-225e-4f4a-9057-3af998b05fdb", "text": "Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. Preprint , arXiv:2106.09685 .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 198}, {"uuid": "82c05424-aded-4dce-a18d-51ba38761aaa", "text": "Kalervo J\u00e4rvelin and Jaana Kek\u00e4l\u00e4inen. 2002. Cumulated gain-based evaluation of ir techniques. ACM Transactions on Information Systems (TOIS) , 20(4):422-446.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 158}, {"uuid": "057b56af-c6f5-4dff-95b5-d8b0d23544c7", "text": "CheonSu Jeong. 2023. A study on the implementation of generative ai services using an enterprise database llm application architecture. Adv. Artif. Intell. Mach. Learn. , 3:1588-1618.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 183}, {"uuid": "ed736666-e2ac-4861-b96f-bb7314039258", "text": "Lei Kang, Ruben Tito, Ernest Valveny, and Dimosthenis Karatzas. 2024. Multi-page document visual question answering using self-attention scoring mechanism. In Document Analysis and Recognition - ICDAR 2024: 18th International Conference, Athens, Greece, August 30-September 4, 2024, Proceedings, Part VI , page 219-232, Berlin, Heidelberg. Springer-Verlag.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 10, "char_len": 356}, {"uuid": "6739c873-f823-415c-b4f7-6ea33fb269d3", "text": "Jordy Van Landeghem, Rafa\u0142 Powalski, Rub\u00e8n Tito, Dawid Jurkiewicz, Matthew Blaschko, \u0141ukasz Borchmann, Micka\u00ebl Coustaty, Sien Moens, Micha\u0142 Pietruszka, Bertrand Ackaert, Tomasz Stanis\u0142awek, Pawe\u0142 J\u00f3ziak, and Ernest Valveny. 2023. Document understanding dataset and evaluation (dude). In 2023 IEEE/CVF International Conference on Computer Vision (ICCV) , pages 9471-9483.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 370}, {"uuid": "3380d6b4-e608-43f7-b0aa-62ad7987cbc8", "text": "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen tau Yih, Tim Rockt\u00e4schel, Sebastian Riedel, and Douwe Kiela. 2021. Retrieval-augmented generation for knowledgeintensive nlp tasks. Preprint , arXiv:2005.11401.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 289}, {"uuid": "664e53d0-505f-476e-9fe4-77db9d29003f", "text": "Minghao Li, Tengchao Lv, Jingye Chen, Lei Cui, Yijuan Lu, Dinei Florencio, China Zhang, Zhoujun Li, and Furu Wei. 2022. Trocr: Transformer-based optical character recognition with pre-trained models. Preprint , arXiv:2109.10282.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 228}, {"uuid": "a0a0cb55-d756-435e-810c-b0d3d3e32132", "text": "Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out , pages 74-81.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 125}, {"uuid": "ec950255-0147-4a3a-8c07-91bebfedce65", "text": "Jiefeng Ma, Jun Du, Pengfei Hu, Zhenrong Zhang, Jianshu Zhang, Huihui Zhu, and Cong Liu. 2023. Hrdoc: dataset and baseline method toward hierarchical reconstruction of document structures. In Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirtyth Symposium on Educational Advances in Artificial Intelligence , AAAI'23/AAI'23/EAAI'23. AAAI Press.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 462}, {"uuid": "64ba4076-c8c2-4ab4-9e59-5d7a1a8bb50f", "text": "Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar. 2022. Doclaynet: A large human-annotated dataset for documentlayout segmentation. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining , KDD '22, page 3743-3751, New York, NY, USA. Association for Computing Machinery.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 335}, {"uuid": "d19917e0-5197-45b2-bf37-2364b2d0735b", "text": "Renyi Qu, Ruixuan Tu, and Forrest Sheng Bao. 2025. Is semantic chunking worth the computational cost? In Findings of the Association for Computational Linguistics: NAACL 2025 , pages 2155-2177, Albuquerque, New Mexico. Association for Computational Linguistics.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 261}, {"uuid": "2f5e9e2b-55d5-45bf-a169-5790917c0092", "text": "Johannes Rausch, Octavio Martinez, Fabian Bissig, Ce Zhang, and Stefan Feuerriegel. 2021. Docparser: Hierarchical document structure parsing from renderings. Proceedings of the AAAI Conference on Artificial Intelligence , 35:4328-4338.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 235}, {"uuid": "ba3f4367-17e4-44d6-b9b9-dc863aed7bdf", "text": "Johannes Rausch, Gentiana Rashiti, Maxim Gusev, Ce Zhang, and Stefan Feuerriegel. 2023. Dsg: An end-to-end document structure generator.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 136}, {"uuid": "56d0da3e-4c5a-45a5-b358-74cbb260b48e", "text": "Stephen Robertson and Hugo Zaragoza. 2009. The probabilistic relevance framework: Bm25 and beyond. Found. Trends Inf. Retr., 3(4):333-389.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 138}, {"uuid": "fdd2ca8a-13a7-4252-9a06-139949c7a590", "text": "Jon Saad-Falcon, Joe Barrow, Alexa Siu, Ani Nenkova, David Seunghyun Yoon, Ryan A. Rossi, and Franck Dernoncourt. 2023. Pdftriangle: Question answering over long, structured documents. Preprint , arXiv:2309.08872.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 213}, {"uuid": "4d19902f-1fa6-461a-a8a4-17fe950ae65a", "text": "R. Smith. 2007. An overview of the tesseract ocr engine. In Ninth International Conference on Document Analysis and Recognition (ICDAR 2007) , volume 2, pages 629-633.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 167}, {"uuid": "62638d2f-ada7-42a3-9a9c-4561f98136b4", "text": "Seyed Amin Tabatabaei, Sarah Fancher, Michael Parsons, and Arian Askari. 2025. Can large language models serve as effective classifiers for hierarchical multi-label classification of scientific documents at industrial scale? In Proceedings of the 31st International Conference on Computational Linguistics: Industry Track , pages 163-174, Abu Dhabi, UAE. Association for Computational Linguistics.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 397}, {"uuid": "5e170ce5-26a5-4ba7-a7cb-99a01c661950", "text": "Ruben Tito, Dimostenis Karatzas, and Ernest Valveny. 2023. Hierarchical multimodal transformers for multi-page docqa. Preprint , arXiv:2212.05935.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 146}, {"uuid": "da1137d7-dcb4-4aab-a063-0fe60cae1cf2", "text": "D.R. Vedhaviyassh, R. Sudhan, G. Saranya, M. Safa, and D. Arun. 2022. Comparative analysis of easyocr and tesseractocr for automatic license plate recognition using deep learning algorithm. In 2022 6th International Conference on Electronics, Communication and Aerospace Technology , pages 966-971.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 298}, {"uuid": "b3c73fbb-4ba3-4dff-9305-e29f3e039aa1", "text": "Prashant Verma, 2025. S2 chunking: A hybrid framework for document segmentation through integrated spatial and semantic analysis. Preprint , arXiv:2501.05485.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 158}, {"uuid": "74120e2c-e028-4ed5-97ad-0d926bd62d64", "text": "Dongsheng Wang, Natraj Raman, Mathieu Sibue, Zhiqiang Ma, Petr Babkin, Simerjot Kaur, Yulong Pei, Armineh Nourbakhsh, and Xiaomo Liu. 2024a. DocLLM: A layout-aware generative language model for multimodal document understanding. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Paper) , pages 8529-8548, Bangkok, Thailand. Association for Computational Linguistics.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 423}, {"uuid": "4f752d09-1697-4f7a-a187-06d3bdb85e6d", "text": "Jiawei Wang, Kai Hu, Zhuoyao Zhong, Lei Sun, and Qiang Huo. 2024b. Detect-order-construct: A tree construction based approach for hierarchical document structure analysis. Pattern Recognition , 156:110836.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 205}, {"uuid": "677c9e4d-5fca-431e-88e2-7622b9bc5fe9", "text": "Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei. 2024c. Multilingual e5 text embeddings: A technical report. Preprint , arXiv:2402.05672.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 170}, {"uuid": "404a32fb-699f-4c31-91a3-028a3d53bd8d", "text": "Hangdi Xing, Changxu Cheng, Feiyu Gao, Zirui Shao, Zhi Yu, Jiajun Bu, Qi Zheng, and Cong Yao. 2024. Dochieten: A large and diverse dataset for document hierarchy parsing. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP) .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 11, "char_len": 270}, {"uuid": "11936030-22cc-472b-95bc-7e43ea803ca0", "text": "An Yang, Baosong Yang, Bingyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, and Zhihao Fan. 2024. Qwen2 technical report. arXiv preprint arXiv:2407.10671 .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 162}, {"uuid": "fa9b7cb5-00f3-4302-9087-d3c8da499a45", "text": "Antonio Jimeno Yepes, Yao You, Jan Milczek, Sebastian Laverde, and Renyu Li. 2024. Financial report chunking for effective retrieval augmented generation. Preprint , arXiv:2402.05131.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 183}, {"uuid": "c0aad88b-4246-4a66-a46f-e28b18cbd271", "text": "Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, and Guoyin Wang. 2024a. Instruction tuning for large language models: A survey. Preprint , arXiv:2308.10792.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 227}, {"uuid": "4a2acbcf-c1a2-4c39-aa8e-45e8be454143", "text": "Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, and Yulia Tsvetkov. 2024b. Can LLM graph reasoning generalize beyond pattern memorization? In Findings of the Association for Computational Linguistics: EMNLP 2024 , pages 2289-2305, Miami, Florida, USA. Association for Computational Linguistics.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 329}, {"uuid": "4034cad6-fa37-460b-b20c-e25a46d34188", "text": "Yue Zhang, Zhihao Zhang, Wenbin Lai, Chong Zhang, Tao Gui, Qi Zhang, and Xuanjing Huang. 2024c. PDF-to-tree: Parsing PDF text blocks into a tree. In Findings of the Association for Computational Linguistics: EMNLP 2024 , pages 10704-10714, Miami, Florida, USA. Association for Computational Linguistics.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 303}, {"uuid": "47ff15f0-a09c-466b-ba97-8f0af26e38a1", "text": "Jihao Zhao, Zhiyuan Ji, Pengnian Qi, Simin Niu, Bo Tang, Feiyu Xiong, and Zhiyu li. 2024. Metachunking: Learning efficient text segmentation via logical perception.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 164}, {"uuid": "16f1711f-061e-4101-825e-2e3cfc3c5c8f", "text": "Xu Zhong, Elaheh ShafieiBavani, and Antonio Jimeno Yepes. 2020. Image-based table recognition: data, model, and evaluation. In European Conference on Computer Vision (ECCV) , pages 564-580. Springer.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 199}, {"uuid": "56a77340-76f6-4e66-b396-838f480cee54", "text": "This appendix complements the main text and provides a concise roadmap for reproduction and inspection of results.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 114}, {"uuid": "680fbca1-a656-4b3f-ab75-678f4e9240a9", "text": "Table 7: Summary of key datasets used in MultiDocFusion.", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 56}, {"uuid": "c4df4b6f-66cd-4ce7-bab2-878c5474f205", "text": "(A) Datasets for DSHP-LLM Training and Evaluation DocHieNet and HRDH include annotations of hierarchical section structures (parent-child relationships) within documents, making them suitable for training the DSHP-LLM model.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 224}, {"uuid": "c988e642-9397-40ac-9885-c33175bbd16c", "text": "(B) Multi-page VQA Datasets The datasets MPVQA , CUAD , DUDE , and MOAMOB were utilized for practical RAG-based Question Answering (QA) experiments. These datasets include various document formats and layouts, such as indu-", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 12, "char_len": 223}, {"uuid": "21acc1e8-6de5-4b82-9e93-d97eea88a4e7", "text": "trial reports, legal contracts, and financial documents.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 13, "char_len": 56}, {"uuid": "1abff400-bbd2-49d7-a817-b63a6d022d4c", "text": "$^{1}$https://rrc.cvc.uab.es/?ch=23", "label": "footnote", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 13, "char_len": 35}, {"uuid": "f0138ae9-5589-42c7-84b3-33249be6ff94", "text": "$^{2}$https://rrc.cvc.uab.es/?ch=17", "label": "footnote", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 13, "char_len": 35}, {"uuid": "b309327a-7d41-473d-ac2f-0634cd496327", "text": "and challenging questions provide a rigorous evaluation under constrained conditions.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 13, "char_len": 85}, {"uuid": "ebec83d2-c59e-4b4c-8dff-4d46ebed7bd3", "text": "Language Information: DocHieNet consists of English and Chinese documents, MOAMOB contains Korean documents, and all other datasets are in English.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 13, "char_len": 147}, {"uuid": "3667a831-6007-4f01-833e-e8464b90bcc7", "text": "In our experiments, we cross-applied multiple models for each pipeline component to verify the robustness of the proposed MultiDocFusion pipeline across realistic scenarios with varied performance.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 13, "char_len": 197}, {"uuid": "aecb6c86-96e6-4899-b0e7-d181760ef25a", "text": "Hardware and Software Environment Experiments were conducted on a single NVIDIA A100 40GB GPU , with an Intel Xeon 32-core CPU and 25GB RAM. Model training and inference utilized PyTorch 2.0 and the Transformers library. Embedding inference was batch-processed in a CPU/GPU hybrid environment.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 293}, {"uuid": "a2fb31b9-dafa-449b-8d35-2c1452d813ee", "text": "Hyperparameters For DSHP-LLM training, the baseline hyperparameters were set as epochs=5, batch size=16, learning rate=1 \u00d7 10 - $^{5}$, with further tuning via grid search. Retrieval utilized a default top-k of 4, with BM25 parameters k_1=1.2, b=0.75. To maintain experimental consistency and adhere to the embedding model's context length constraints, the maximum chunk length ( max_len ) was fixed at 550 tokens, following prior studies (Duarte et al., 2024; Hong et al., 2024; Yepes et al., 2024).", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 500}, {"uuid": "10b6b0ad-b646-46e6-b15a-7b88181c27d5", "text": "This section provides comprehensive descriptions of the chunking methodologies compared against our proposed MultiDocFusion pipeline.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 133}, {"uuid": "c7dd938b-0cd5-41b5-840b-a398728226db", "text": "Length chunking (Gong et al., 2020) This method divides documents into chunks based on a fixed token length limit. Each chunk is created uniformly, without considering semantic or structural boundaries. While simple and computationally efficient, it risks splitting important contexts, leading to potential information loss and degraded performance in retrieval and QA tasks.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 375}, {"uuid": "75643eb8-f8d4-481c-9257-c87232d8cf1b", "text": "Semantic chunking (Qu et al., 2025) Semantic chunking leverages encoder-based language models to maintain semantic consistency. Chunks are formed by grouping sentences based on semantic similarity scores derived from language models (e.g., E5 embeddings). Although effective in maintaining semantic coherence, it tends to produce shorter, numerous chunks, potentially impacting retrieval efficiency. Following prior work (Hong et al., 2024), we employed the E5 model for consistency in our experiments.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 502}, {"uuid": "a11a67c3-adce-45c6-8ddd-13fb851be02e", "text": "LumberChunker (Duarte et al., 2024) LumberChunker employs Large Language Models (LLMs) to dynamically partition documents by identifying topical shifts between sentences or paragraphs. It effectively captures the semantic independence of textual segments, resulting in", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 268}, {"uuid": "73f9bdfd-49ba-4624-a6c8-d41bfd5819c0", "text": "chunks of variable sizes optimized for dense retrieval tasks. For experimental consistency across LLM-based methods, we employed the Mistral8B model as the base model.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 167}, {"uuid": "79a6ac06-4e35-48f3-868e-805f1bc4f0b9", "text": "Perplexity chunking (Zhao et al., 2024) Based on the concept of Meta-Chunking, Perplexity chunking identifies optimal chunk boundaries by analyzing the perplexity distribution of sentences and paragraphs. It dynamically merges or splits textual segments at a fine-grained level, effectively balancing granularity and computational efficiency. To ensure fairness among LLM-based methods, we also used the Mistral-8B model for these experiments.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 443}, {"uuid": "2645c0fd-e853-4c90-8d56-53739a3e7459", "text": "This approach partitions documents solely based on their structural layouts, such as section headers, tables, and figures. Similar methodologies have been explored in recent works (Yepes et al., 2024; Verma, 2025). In our experiments, Structure-based Chunking served as a baseline to clearly isolate and demonstrate the impact of the proposed DSHP-LLM. Specifically, chunks were created by ordering structural elements obtained via DP (Document Parsing), without explicitly considering hierarchical parent-child relationships identified by DSHP-LLM. Segment types were included in the resulting chunks.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 602}, {"uuid": "a4acc0f7-16d9-46c0-a6d8-7efcafb06908", "text": "MultiDocFusion Our proposed multimodal chunking pipeline integrates hierarchical document structure into the chunking process. It utilizes the best-performing DSHP-LLM model (fine-tuned Mistral-8B) identified from our previous experiments to explicitly reconstruct section hierarchies, significantly enhancing the semantic and structural coherence of document chunks and thus improving retrieval and QA outcomes.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 412}, {"uuid": "9fa96f5e-e48b-4a69-8bce-0802c5056caa", "text": "Table 8 summarizes the chunking statistics for the six evaluated chunking methods. Length chunking consistently generates chunks close to the predefined maximum token length. Semantic chunking tends to produce the shortest and highest number of chunks. LumberChunker and Perplexity methods yield intermediate chunk sizes and counts, whereas Structure-based chunking produces relatively longer chunks by explicitly including segment types.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 14, "char_len": 438}, {"uuid": "ff0d01fe-45d2-4a17-bbfb-6315190c972e", "text": "Table 8: Chunk statistics (average length and total number) for Length chunking, Semantic chunking, LumberChunker, Perplexity, Structure-based, and MultiDocFusion chunking methods ( max_len=550 tokens)", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 201}, {"uuid": "1973bb13-fc1b-40b8-b1cd-004ab48f786c", "text": "The proposed MultiDocFusion generates the highest number of chunks (20,773), each of which tends to approach the maximum token length (averaging 766.85 characters and 521.65 tokens). This increase results from the hierarchical approach where chunks with identical parent headers include duplicated content. Despite generating more chunks, MultiDocFusion consistently achieves superior retrieval performance, demonstrating the effectiveness of fine-grained, hierarchical chunking in retrieving relevant context.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 510}, {"uuid": "02d035ea-0946-4faa-bd8d-b65f3b2e753a", "text": "Tables 2, 12, 13, 14, 15, 16 extend the summarized results presented in the main text, providing comprehensive comparisons across topk = 1 \u223c 4 , DP models, OCR models, and embedding models. Consistent with the summarized experiments, these detailed tables further confirm that the MultiDocFusion pipeline consistently outperforms other chunking methods across diverse datasets and industrial document scenarios, highlighting its robust chunking performance.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 457}, {"uuid": "e0600981-0f64-47f7-bbb6-4d5c50734662", "text": "Official test-server result on Table 9", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 38}, {"uuid": "1acc6a6b-017a-4248-911f-282deb4cfb0f", "text": "The DFS-based algorithm traverses the parsed hierarchy_tree in a Depth-First Search manner, accumulating text from parent to child sections. When the accumulated text exceeds max_len , it splits appropriately to create new chunks. This method efficiently maintains the hierarchical document structure while managing the chunk length constraint.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 344}, {"uuid": "51178b28-333c-47e3-8cad-18e0ad76207a", "text": "Table 9: Official test-server ANLS on DUDE and MPVQA. Ground-truth is hidden on the server, so retrieval metrics cannot be computed; main paper reports corpus-level retrieval+QA on validation splits.", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 199}, {"uuid": "946819d4-562b-4fa5-a6a1-438d8d2af543", "text": "Algorithm 1 DFS-based Hierarchical Chunking Algorithm (Conceptual Summary)", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 74}, {"uuid": "964a6a15-1377-4517-b700-c9b5c908a7f8", "text": "Require: hierarchy_tree , max_len", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 33}, {"uuid": "d963c5db-c5b1-4c64-b8f6-3729bc5ed919", "text": "1: function DFS_CHUNKING( node , context )", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 42}, {"uuid": "cee0bff9-4f64-4c51-828b-a371b706edb9", "text": "2:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 2}, {"uuid": "21204f1e-b251-4733-b3ef-296dadc2d686", "text": "currentText \u2190 node.text", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 23}, {"uuid": "233ad126-e821-480f-949e-f4617092992c", "text": "3:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 2}, {"uuid": "f638c3e1-ae04-4465-911b-4b83c9c394b9", "text": "temp \u2190 context + currentText", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 28}, {"uuid": "a5f18e79-7bbc-4814-9f11-6d01c07fd6b1", "text": "4:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 2}, {"uuid": "f4991fce-4920-45f9-bba5-79f389adb3b5", "text": "if length( temp ) > max_len then", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 32}, {"uuid": "c77f032c-cf87-4474-b547-3026d09f8cc9", "text": "5:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 2}, {"uuid": "22a6cc27-4301-45c3-bf4e-90f7705843f8", "text": "Split temp into multiple chunks", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 31}, {"uuid": "6c1c166f-ad0d-4700-8c3e-7fd7e618947f", "text": "6:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 2}, {"uuid": "ffa7f6c2-69d8-4f91-af87-a9a6b8d408f7", "text": "else", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 4}, {"uuid": "eadedb66-daf5-4467-b787-8036dddd8c20", "text": "7:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 2}, {"uuid": "6aa79922-b486-45ab-a7d4-d6443e2eb708", "text": "Append temp to chunk list", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 25}, {"uuid": "3530b122-3dc1-4af4-add4-93581c63fa8a", "text": "8:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 2}, {"uuid": "6e789eac-17ab-45a6-a3dd-db116a06da67", "text": "end if", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 6}, {"uuid": "1cc74483-5d8b-4e51-9873-570487b8b1a1", "text": "9:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 2}, {"uuid": "5ec43cff-fea4-4aee-8f39-5ae06f3c85fa", "text": "for child \u2208 node.children do", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 28}, {"uuid": "f04e4dd7-849a-43f6-8473-f3451be2e6f1", "text": "10:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 3}, {"uuid": "9a6d81ee-db70-4ef1-87d0-8f12cba230b9", "text": "DFS_CHUNKING( child , temp )", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 28}, {"uuid": "cb1d6f97-328d-4629-8e5c-6c8f396f7101", "text": "11:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 3}, {"uuid": "7a4e27c1-6ab6-450c-a175-9be531cfe6cd", "text": "end for", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 7}, {"uuid": "30e600b8-4a6a-481b-8616-7dae574e335e", "text": "12:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 3}, {"uuid": "3ce5a8be-2944-41c1-8916-a182b4c97f9a", "text": "end function", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 12}, {"uuid": "4b1326a6-0dfa-47dd-a0fc-1c182f43f252", "text": "13:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 3}, {"uuid": "0764b90e-0e2b-4383-bf21-7962d8309041", "text": "DFS_CHUNKING( root, \"\" )", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 24}, {"uuid": "f09c3255-7e6f-4625-a512-c2149ed926e5", "text": "Table 10 provides condensed examples of the system prompts , user inputs , and output examples used to instruct the DSHP-LLM model to infer the hierarchical structure of document headers. In training, hundreds or thousands of header lists paired with corresponding JSON ground truths are employed.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 297}, {"uuid": "0cebcf58-2b5e-45ae-b8a9-4058f5ef7035", "text": "Table 11 presents the results of applying each chunking method to the document shown in Figure 2. Conventional text-based chunking approaches (Length, Semantic, LumberChunker, Perplexity) often lack clear segmentation criteria between chunks and frequently fail to maintain contextual continuity. In contrast, our proposed method includes higher-level hierarchical nodes within each chunk, thereby preserving contextual coherence and enabling the generation of wellstructured, hierarchically organized chunks.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 15, "char_len": 509}, {"uuid": "66e92277-7ae5-4b5b-bc5d-b8a3ffccde19", "text": "You are an expert in analyzing section headers of documents and creating a hierarchical structure. The following is a list of 'section header' texts extracted from a document.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 175}, {"uuid": "7820c8e8-4f64-4296-b8a4-e2b2f58962dd", "text": "For each item, determine its relationship with the parent section (parent-child relationship).", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 94}, {"uuid": "2cd1dfac-7aaf-4c59-a90e-c91b8bcf7387", "text": "If possible, follow standard document numbering rules, such as treating '3.1' as a child of '3' and '3.1.1' as a child of '3.1'.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 128}, {"uuid": "e24e1aeb-7280-473c-a310-2f050dfaacc1", "text": "Even if there is no numeric pattern, infer hierarchy based on textual context.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 78}, {"uuid": "95f60de4-1465-4787-8b15-5b26bb6fbf44", "text": "If an item is a top-level heading (i.e., the root node is its parent), set 'parent' to null.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 92}, {"uuid": "84efb5ba-e325-4e2f-805a-e0e41fe978a0", "text": "Output format:", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 14}, {"uuid": "eef6839f-5cf1-420f-b567-97f658a087ca", "text": "json only.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 10}, {"uuid": "9b57c35c-e1fc-4315-9951-6e0a169cf3bf", "text": "DO NOT include any other explanations or text.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 46}, {"uuid": "cd454c15-20cd-4918-989f-1d6e5a6baac5", "text": "[", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 1}, {"uuid": "a60e9fd6-e6d9-4adf-bb53-b6090b27adbe", "text": "{\"id\": \"\", \"parent\": \"\"}", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 24}, {"uuid": "ec6d363c-6512-43cf-a742-d77d6d7bdd9e", "text": "]", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 1}, {"uuid": "1a2459d9-4b99-4b78-b443-1e77d2d4a7ed", "text": "Example 1 (HRDH)\n        ### User:\n        { \"id\": \"2\", \"text\": \"1. Introduction\",  { \"id\": \"2\", \"text\": \"CONGRESSIONAL\n    \"page_number\": 0, \"top\": 395, \"left\":\n    257 },\n    { \"id\": \"3\", \"text\": \"2. The puzzle\",\n    \"page_number\": 1, \"top\": 659, \"left\":\n    263 },\n    { \"id\": \"4\", \"text\": \"3. Next section\",\n    ...},\n    { \"id\": \"5\", \"text\": \"4. Another\n    topic\", ...},\n    { \"id\": \"6\", \"text\": \"4.1 Subtopic of\n    4\", ...},\n    { \"id\": \"7\", \"text\": \"5. Additional\n    info\", ...},\n    ...\n\n\n        ### Assistant:\n        { \"id\": \"2\", \"parent\": null },\n        { \"id\": \"3\", \"parent\": \"2\" },\n        { \"id\": \"4\", \"parent\": \"3\" },\n        { \"id\": \"5\", \"parent\": \"4\" },\n        { \"id\": \"6\", \"parent\": \"5\" },\n        { \"id\": \"7\", \"parent\": \"5\" },\n        ...\n\n\n        Table 10: Prompt examples for DSHP-LLM model training. The common prompt (top) is used for both Example", "label": "code", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 877}, {"uuid": "af8f7dd5-6188-4d8e-a106-8215776df4b6", "text": "Table 10: Prompt examples for DSHP-LLM model training. The common prompt (top) is used for both Example 1 (easier, with numbered sections) and Example 2 (harder, no section numbers). Lines expanded so that both examples reach a similar height. The parent value null denotes the root node. The symbol ... indicates omitted content for brevity.", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 16, "char_len": 342}, {"uuid": "f9f33a75-a26c-41b1-ab1d-42aebf3c9773", "text": "Figure 2: An example of a long industrial document (MPVQA) illustrating the content structure and formatting used for guidelines and requirements in nuclear power plant operations. The document contains various sections, such as general information, application scope, and specific criteria, serving as a representative case for evaluating document chunking methods.", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 17, "char_len": 366}, {"uuid": "1d795b2c-8637-4c04-b9bf-b97489f60c86", "text": "(a) Document Parsing example - page-level layout regions (titles, headers, text blocks, tables, figures) detected by DP.", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 17, "char_len": 120}, {"uuid": "dcf71492-c993-47bc-a7bd-241e569750c1", "text": "(c) DSHP-LLM example - section headers parsed into a document hierarchical tree with parent-child links; general nodes attached by spatial order.", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 17, "char_len": 145}, {"uuid": "4a00eb38-a68b-44e2-8fd8-51bd43b11b2d", "text": "Figure 3: Step-by-step illustration aligned with the MultiDocFusion pipeline: (a) Document Parsing (DP), (b) OCR, (c) DSHP-LLM for section hierarchy reconstruction and node attachment, and (d) DFS-based Grouping for hierarchy-aware chunking.", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 17, "char_len": 241}, {"uuid": "0b0ce9ad-f8d8-4ac7-88a0-e0d980e8f018", "text": "Table 11: Qualitative comparison of chunking methods applied to the document in Figure 2. Each method shows three chunks (1 to 3) for six approaches: Length chunking, Semantic chunking, LumberChunker, Perplexity chunking, Structure-based chunking, and MultiDocFusion .", "label": "text", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 18, "char_len": 268}, {"uuid": "f743df10-e58b-4718-9df8-2ffb30ee9d71", "text": "Table 12: Retrieval summary by Chunking Method - Comparison of VQA Datasets (topk = 1 \u223c 4 )", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 19, "char_len": 91}, {"uuid": "d002d6f9-99b2-4097-8ede-670b94a966c2", "text": "Table 13: OCR performance by Chunking Method (topk = 1 \u223c 4 average)", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 19, "char_len": 67}, {"uuid": "48430476-105f-49fa-893a-6d20ffa4ecbc", "text": "Table 14: DP performance by Chunking Method (top \ud835\udc58 = 1 \u223c 4 average)", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 20, "char_len": 67}, {"uuid": "9704f0a9-ff05-46cd-b211-bd8ac43909b9", "text": "Table 15: Performance comparison by Embedding and Chunking Method (top \ud835\udc58 = 1 \u223c 4 average)", "label": "caption", "section_path": ["6 Conclusion"], "section_refs": ["#/texts/79"], "page_no": 20, "char_len": 89}]
